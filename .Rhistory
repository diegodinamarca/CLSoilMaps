eaFit <- ea_spline(testbd, var.name = var,
d = t(c(0, 5, 15, 30, 60, 100, 200)), lam = lambda, vlow = 0,
show.progress = F)
}else {
eaFit <- ea_spline(testbd, var.name = var,
d = t(c(0, 5, 15, 30, 60, 100, 200)), lam = lambda, vlow = 0, vhigh = 100,
show.progress = F)
}
# Export Harmonized database
harm <- eaFit$harmonised
index <- match(harm$id, bd$ID)
harm$x <- bd$x[index]
harm$y <- bd$y[index]
harm$Fuente <- bd$Fuente[index]
harm[harm == -9999] <- NA
#Write result
fname = paste0(var,"_standard.csv")
write_csv(harm,here("proc","soil_database","standard",fname))
}
for (i in 1:5){
#iterate through databases
bd <- bd.list[[i]]
var <- variables[i]
nro_Reg <- nrow(bd);nro_Reg
# Clean database
bd <- bd[which(bd[[6]] != -999), ]
bd <- bd[which(bd$Tratamiento == "testigo"), ]
#Define SoilProfile database
data <- bd
depths(data) <- ID ~ top + bottom
#smoothing parameter
lambda <- c(10, 1, 0.1, 0.01, 0.001,0.0001,0.00001)
#GET RMSE for each lambda
rmse_models <- sapply(lambda, function(x){
tryCatch({
# x <- 10
eaFit <- ea_spline(data, var.name = var, #CAMBIAR COLUMNA SEGUN PROPIEDAD
d = t(c(0, 5, 15, 30, 60, 100, 200)), lam = x, vlow = 0, vhigh = 100,
show.progress = TRUE)
# plot(eaFIT, plot.which = 100)
obs <- as.numeric(eaFit$obs.preds[[4]]) #CAMBIAR SEGUN PROPIEDAD
pred <- eaFit$obs.preds$predicted
rmse <- RMSE(pred, obs)
res <- rmse},
error = function(w){
print(paste0("Error fitting splines for lambda = ", x))
res <- 9999
})
})
#Para el modelo de Da, A, L y a, el mejor RMSE fue del modelo con lambda 0.00001
print(rmse_models)
#Extract lambda with lowest RMSE
lambda <- lambda[which.min(rmse_models)]
cat(var_names_eng[var], ": Selected Model lambda = ", lambda,"\n")
# Get final results
if (var == "Da"){
eaFit <- ea_spline(data, var.name = var,
d = t(c(0, 5, 15, 30, 60, 100, 200)), lam = lambda, vlow = 0,
show.progress = F)
}else {
eaFit <- ea_spline(data, var.name = var,
d = t(c(0, 5, 15, 30, 60, 100, 200)), lam = lambda, vlow = 0, vhigh = 100,
show.progress = F)
}
# Export Harmonized database
harm <- eaFit$harmonised
index <- match(harm$id, bd$ID)
harm$x <- bd$x[index]
harm$y <- bd$y[index]
harm$Fuente <- bd$Fuente[index]
harm[harm == -9999] <- NA
#Write result
fname = paste0(var,"_standard.csv")
write_csv(harm,here("proc","soil_database","standard",fname))
}
# Constants
variables <- c("Da","A","a","MO","L")
var_names_eng <- c( "Da" ="Bulk Density","Arcilla"= "Clay","arena" = "Sand","Limo" = "Silt", "MO"= "Organic Matter")
var_names_esp <- c( "Da" = "Da","A"= "Arcilla","a" = "arena","L" = "Limo", "MO" = "MO")
depths <- c('0-5 cm','5-15 cm','15-30 cm', "30-60 cm","60-100 cm","100-200 cm")
for (i in 1:5){
#iterate through databases
bd <- bd.list[[i]]
var <- variables[i]
nro_Reg <- nrow(bd);nro_Reg
# Clean database
bd <- bd[which(bd[[6]] != -999), ]
bd <- bd[which(bd$Tratamiento == "testigo"), ]
#Define SoilProfile database
data <- bd
depths(data) <- ID ~ top + bottom
#smoothing parameter
lambda <- c(10, 1, 0.1, 0.01, 0.001,0.0001,0.00001)
#GET RMSE for each lambda
rmse_models <- sapply(lambda, function(x){
tryCatch({
# x <- 10
eaFit <- ea_spline(data, var.name = var, #CAMBIAR COLUMNA SEGUN PROPIEDAD
d = t(c(0, 5, 15, 30, 60, 100, 200)), lam = x, vlow = 0, vhigh = 100,
show.progress = TRUE)
# plot(eaFIT, plot.which = 100)
obs <- as.numeric(eaFit$obs.preds[[4]]) #CAMBIAR SEGUN PROPIEDAD
pred <- eaFit$obs.preds$predicted
rmse <- RMSE(pred, obs)
res <- rmse},
error = function(w){
print(paste0("Error fitting splines for lambda = ", x))
res <- 9999
})
})
#Para el modelo de Da, A, L y a, el mejor RMSE fue del modelo con lambda 0.00001
print(rmse_models)
#Extract lambda with lowest RMSE
lambda <- lambda[which.min(rmse_models)]
cat(var_names_eng[var], ": Selected Model lambda = ", lambda,"\n")
# Get final results
if (var == "Da"){
eaFit <- ea_spline(data, var.name = var,
d = t(c(0, 5, 15, 30, 60, 100, 200)), lam = lambda, vlow = 0,
show.progress = F)
}else {
eaFit <- ea_spline(data, var.name = var,
d = t(c(0, 5, 15, 30, 60, 100, 200)), lam = lambda, vlow = 0, vhigh = 100,
show.progress = F)
}
# Export Harmonized database
harm <- eaFit$harmonised
index <- match(harm$id, bd$ID)
harm$x <- bd$x[index]
harm$y <- bd$y[index]
harm$Fuente <- bd$Fuente[index]
harm[harm == -9999] <- NA
#Write result
fname = paste0(var,"_standard.csv")
write_csv(harm,here("proc","soil_database","standard",fname))
}
A
A
a
# Load database
db_soilprof <- read_csv(here("data","soil_database","BD_soilprof_26ENE.csv"))
names(db_soilprof)
db_soilprof %>% select(ID, x, y, top, bottom, bulkd = Da, clay = A, silt = L, sand = a, OM = MO)
conflicted::conflict_prefer(dplyr::select)
conflicted::conflict_prefer(dplyr::select())
conflicted::conflict_prefer("select", winner = "dplyr")
db_soilprof %>% select(ID, x, y, top, bottom, bulkd = Da, clay = A, silt = L, sand = a, OM = MO)
db = db_soilprof %>% select(ID, x, y, top, bottom, bulkd = Da, clay = A, silt = L, sand = a, OM = MO)
var_names_eng <- c( "bulkd" ="Bulk Density","clay"= "Clay","sand" = "Sand","silt" = "Silt", "OM"= "Organic Matter")
# var_names_esp <- c( "Da" = "Da","A"= "Arcilla","a" = "arena","L" = "Limo", "MO" = "MO")
depths <- c('0-5 cm','5-15 cm','15-30 cm', "30-60 cm","60-100 cm","100-200 cm")
#iterate through databases
# bd <- bd.list[[i]]
var <- variables[i]
var
db = db_soilprof %>% select(ID, x, y, top, bottom, bulkd = Da, clay = A, silt = L, sand = a, OM = MO)
# Constants
variables <- c("bulkd","clay","sand","silt","OM")
var_names_eng <- c( "bulkd" ="Bulk Density","clay"= "Clay","sand" = "Sand","silt" = "Silt", "OM"= "Organic Matter")
# var_names_esp <- c( "Da" = "Da","A"= "Arcilla","a" = "arena","L" = "Limo", "MO" = "MO")
depths <- c('0-5 cm','5-15 cm','15-30 cm', "30-60 cm","60-100 cm","100-200 cm")
#iterate through databases
# bd <- bd.list[[i]]
var <- variables[i]
var
#iterate through databases
# bd <- bd.list[[i]]
i=1
var <- variables[i]
var
filter(db, var != -999)
conflicted::conflict_prefer("filter", winner = "dplyr")
filter(db, var != -999)
var
filter(db, all_of(var) != -999)
db[which(db[[var]] != -999)]
db[which(db[[var]] != -999),]
db = db_soilprof %>%
filter(treatment == "testigo") %>%
select(ID, x, y, top, bottom, bulkd = Da, clay = A, silt = L, sand = a, OM = MO)
db = db_soilprof %>%
filter(Tratamiento == "testigo") %>%
select(ID, x, y, top, bottom, bulkd = Da, clay = A, silt = L, sand = a, OM = MO)
db[which(db[[var]] != -999),]
db = db[which(db[[var]] != -999),]
depths(data) <- ID ~ top + bottom
#smoothing parameter
lambda <- c(10, 1, 0.1, 0.01, 0.001,0.0001,0.00001)
stand_soilatt = function(obs.data, var, lambda, vlow = 0, vhigh = 1){
require(aqp)
require(ithir)
#Define SoilProfile database
depths(obs.data) = ID ~ top + bottom
#smoothing parameter
lambda.l <- c(10, 1, 0.1, 0.01, 0.001,0.0001,0.00001)
#GET RMSE for each lambda
rmse_models <- sapply(lambda.l, function(x){
tryCatch({
# x <- 10
eaFit <- ea_spline(obs.data, var.name = var, #CAMBIAR COLUMNA SEGUN PROPIEDAD
d = t(c(0, 5, 15, 30, 60, 100, 200)), lam = x, vlow = vlow, vhigh = vhigh,
show.progress = TRUE)
print(paste0("lambda: ",x, " RMSE: ",round(eaFit$splineFitError$rmse %>% mean,3)))
obs <- as.numeric(eaFit$obs.preds[[4]])
pred <- eaFit$obs.preds$predicted
rmse <- RMSE(pred, obs)
res <- rmse},
error = function(w){
print(paste0("Error fitting splines for lambda = ", x))
res <- 9999
})
})
# Get final results
eaFit <- ea_spline(obs.data, var.name = var,
d = t(c(0, 5, 15, 30, 60, 100, 200)), lam = lambda, vlow = vlow, vhigh = vhigh,
show.progress = F)
return(eaFit)
}
max(db$bulkd)
harm = stand_soilatt(data, var, 0.01, vlow = 0, vhigh = 2.5)
#Define SoilProfile database
data <- db
depths(data) <- ID ~ top + bottom
harm = stand_soilatt(data, var, 0.01, vlow = 0, vhigh = 2.5)
harm
eaFit = stand_soilatt(data, var, 0.01, vlow = 0, vhigh = 2.5)
# Export Harmonized database
harm <- eaFit$harmonised
index <- match(harm$id, db$ID)
harm$x <- db$x[index]
harm$y <- db$y[index]
harm$Fuente <- db$Fuente[index]
# Export Harmonized database
harm <- eaFit$harmonised
index <- match(harm$id, db_soilprof$ID)
harm$x <- db_soilprof$x[index]
harm$y <- db_soilprof$y[index]
harm$Fuente <- db_soilprof$Fuente[index]
harm[harm == -9999] <- NA
#Write result
fname = paste0(var,"_standard.csv")
write_csv(harm,here("proc","soil_database","standard",fname))
for (i in 1:5){
#iterate through databases
var <- variables[i]
print(var)
# clean non valid records
db = db[which(db[[var]] != -999),]
#Define SoilProfile database
eaFit = stand_soilatt(db, var, 0.01, vlow = 0, vhigh = 2.5)
# Export Harmonized database
harm <- eaFit$harmonised
index <- match(harm$id, db_soilprof$ID)
harm$x <- db_soilprof$x[index]
harm$y <- db_soilprof$y[index]
harm$Fuente <- db_soilprof$Fuente[index]
harm[harm == -9999] <- NA
#Write result
fname = paste0(var,"_standard.csv")
write_csv(harm,here("proc","soil_database","standard",fname))
}
harm %>% pivot_longer( cols = 2:7, names_to = "depth", values_to = var)
harm %>% pivot_longer( cols = 2:7, names_to = "depth", values_to = var) %>%
filter(across(all_of(var)== -9999) )
var
harm %>% pivot_longer( cols = 2:7, names_to = "depth", values_to = var) %>%
filter(across(all_of(var), ~ .== -9999))
# Look for profiles that have -9999 values
w.id = harm %>% pivot_longer( cols = 2:7, names_to = "depth", values_to = var) %>%
filter(if_any(all_of(var), ~ .== -9999)) %>%
.[["id"]] %>%
unique
harm %>% pivot_longer( cols = 2:7, names_to = "depth", values_to = var) %>%
filter(if_any(all_of(var), ~ .== -9999))
#iterate through databases
var <- variables[i]
#iterate through databases
i=1
var <- variables[i]
print(var)
# clean non valid records
db = db[which(db[[var]] != -999),]
#Define SoilProfile database
eaFit = stand_soilatt(db, var, 0.01, vlow = 0, vhigh = 2.5)
# Export Harmonized database
harm <- eaFit$harmonised
index <- match(harm$id, db_soilprof$ID)
harm$x <- db_soilprof$x[index]
harm$y <- db_soilprof$y[index]
harm$Fuente <- db_soilprof$Fuente[index]
# Look for profiles that have -9999 values
w.id = harm %>% pivot_longer( cols = 2:7, names_to = "depth", values_to = var) %>%
filter(if_any(all_of(var), ~ .== -9999)) %>%
.[["id"]] %>%
unique
harm %>% pivot_longer( cols = 2:7, names_to = "depth", values_to = var) %>%
filter(if_any(all_of(var), ~ .== -9999))
# Look for profiles that have -9999 values
w.id = harm %>% pivot_longer( cols = 2:7, names_to = "depth", values_to = var) %>%
filter(if_any(all_of(var), ~ .== -9999)) %>%
.[["id"]] %>%
unique
filter(soilprofiles_data, ID %in% w.id)
here("proc","soil_database",paste0("soilp_wrong_stand_",var,".csv"))
# export observed data for wrong standardized soil profiles
filter(soilprofiles_data, ID %in% w.id) %>%
write_csv(here("proc","soil_database",paste0("soilp_wrong_stand_",var,".csv")))
# Load database
soilprofiles_data <- read_csv(here("data","soil_database","BD_soilprof_26ENE.csv"))
names(soilprofiles_data)
db = soilprofiles_data %>%
filter(Tratamiento == "testigo") %>%
select(ID, x, y, top, bottom, bulkd = Da, clay = A, silt = L, sand = a, OM = MO)
# Constants
variables <- c("bulkd","clay","sand","silt","OM")
var_names_eng <- c( "bulkd" ="Bulk Density","clay"= "Clay","sand" = "Sand","silt" = "Silt", "OM"= "Organic Matter")
# var_names_esp <- c( "Da" = "Da","A"= "Arcilla","a" = "arena","L" = "Limo", "MO" = "MO")
depths <- c('0-5 cm','5-15 cm','15-30 cm', "30-60 cm","60-100 cm","100-200 cm")
for (i in 1:5){
#iterate through databases
# i=1
var <- variables[i]
print(var)
# clean non valid records
db = db[which(db[[var]] != -999),]
#Define SoilProfile database
eaFit = stand_soilatt(db, var, 0.01, vlow = 0, vhigh = 2.5)
# Export Harmonized database
harm <- eaFit$harmonised
index <- match(harm$id, soilprofiles_data$ID)
harm$x <- soilprofiles_data$x[index]
harm$y <- soilprofiles_data$y[index]
harm$Fuente <- soilprofiles_data$Fuente[index]
# Look for profiles that have -9999 values
w.id = harm %>% pivot_longer( cols = 2:7, names_to = "depth", values_to = var) %>%
filter(if_any(all_of(var), ~ .== -9999)) %>%
.[["id"]] %>%
unique
# export observed data for wrong standardized soil profiles
filter(soilprofiles_data, ID %in% w.id) %>%
write_csv(here("proc","soil_database",paste0("soilp_wrong_stand_",var,".csv")))
harm[harm == -9999] <- NA
#Write result
fname = paste0(var,"_standard.csv")
write_csv(harm,here("proc","soil_database","standard",fname))
}
# l <- c(0.1, 0.001,0.001, 0.001, 0.001)
for (i in 1:5){
#iterate through databases
# i=1
var <- variables[i]
print(var)
# clean non valid records
db = db[which(db[[var]] != -999),]
#Define SoilProfile database
eaFit = stand_soilatt(db, var, 0.00001, vlow = 0, vhigh = 2.5)
# Export Harmonized database
harm <- eaFit$harmonised
index <- match(harm$id, soilprofiles_data$ID)
harm$x <- soilprofiles_data$x[index]
harm$y <- soilprofiles_data$y[index]
harm$Fuente <- soilprofiles_data$Fuente[index]
# Look for profiles that have -9999 values
w.id = harm %>% pivot_longer( cols = 2:7, names_to = "depth", values_to = var) %>%
filter(if_any(all_of(var), ~ .== -9999)) %>%
.[["id"]] %>%
unique
# export observed data for wrong standardized soil profiles
filter(soilprofiles_data, ID %in% w.id) %>%
write_csv(here("proc","soil_database",paste0("soilp_wrong_stand_",var,".csv")))
harm[harm == -9999] <- NA
#Write result
fname = paste0(var,"_standard.csv")
write_csv(harm,here("proc","soil_database","standard",fname))
}
source("D:/CLSoilMaps/scripts/data_prep/standarize_soil_profiles.R", echo=TRUE)
# Date:
#
# Script Name:
#
# Script Description: figures and tables for the manuscript
#
# Notes:
#
#
# INSTALL PACKAGES & LOAD LIBRARIES -----------------
cat("INSTALLING PACKAGES & LOADING LIBRARIES... \n\n", sep = "")
packages <- c("tidyverse",
"terra",
"sf",
"here",
"gridExtra",
"raster",
"rasterVis",
"ggpointdensity",
"viridis",
"scico") # list of packages to load
n_packages <- length(packages) # count how many packages are required
new.pkg <- packages[!(packages %in% installed.packages())] # determine which packages aren't installed
# install missing packages
if(length(new.pkg)){
install.packages(new.pkg)
}
# load all requried libraries
for(n in 1:n_packages){
cat("Loading Library #", n, " of ", n_packages, "... Currently Loading: ", packages[n], "\n", sep = "")
lib_load <- paste("library(\"",packages[n],"\")", sep = "") # create string of text for loading each library
eval(parse(text = lib_load)) # evaluate the string to load the library
}
# SET WORKING DIRECTORY -----------------------------
cat("SETTING WORKING DIRECTORY...\n\n", sep = "")
wd <- here::here()
setwd(wd)
cat("WORKING DIRECTORY HAS BEEN SET TO: ", wd, sep = "")
# SET OPTIONS ---------------------------------------
cat("SETTING OPTIONS... \n\n", sep = "")
options(scipen = 999) # turns off scientific notation
options(encoding = "UTF-8") # sets string encoding to UTF-8 instead of ANSI
###################### PARTE 1: FILTRAR DATOS DE 5-15CM PARA CARTOGRAFIAS ####################################
dir = here()
###################### PARTE 1: FILTRAR DATOS DE 5-15CM PARA CARTOGRAFIAS ####################################
dir = here("proc","soil_database","standard")
files <- list.files(dir, pattern = "estandarizada", full.names = T);files
dir
files <- list.files(dir, pattern = "estandarizada", full.names = T);files
files <- list.files(dir, pattern = "standard", full.names = T);files
arcilla <- read_csv(files[grep("clay", files)])
arcilla
arcilla <- read_csv(files[grep("clay", files)])
arena <- read_csv(files[grep("sand", files)])
da <- read_csv(files[grep("bulkd", files)])
limo <- read_csv(files[grep("silt", files)])
# Filtrar datos de 5-15cm
arcilla <- arcilla %>% pivot_longer( cols = 2:7, names_to = "profundidad", values_to = "values") %>%
filter(profundidad == "0-5 cm") %>% drop_na()
arena <- arena %>% pivot_longer( cols = 2:7, names_to = "profundidad", values_to = "values") %>%
filter(profundidad == "0-5 cm") %>% drop_na()
da <- da %>% pivot_longer( cols = 2:7, names_to = "profundidad", values_to = "values") %>%
filter(profundidad == "0-5 cm") %>% drop_na()
limo <- limo %>% pivot_longer( cols = 2:7, names_to = "profundidad", values_to = "values") %>%
filter(profundidad == "0-5 cm") %>% drop_na()
# exportar
write_csv(arcilla, here("proc","soil_database","H1.0_5cm","clay_0_5cm.csv"))
write_csv(arena, here("proc","soil_database","H1.0_5cm","sand_0_5cm.csv"))
write_csv(da, here("proc","soil_database","H1.0_5cm","bulkd_0_5cm.csv"))
write_csv(limo, here("proc","soil_database","H1.0_5cm","silt_0_5cm.csv"))
bd <- read_csv("./materiales/Database/BD_soilprof_23MAR.csv")
bd <- here("data","soil_database","BD_soilprof_23MAR.csv")
tex <- bd %>% filter(Arcilla != -999)
bd <- read_csv(here("data","soil_database","BD_soilprof_23MAR.csv"))
bd <- read_csv(here("data","soil_database","BD_soilprof_23MAR.csv"))
tex <- bd %>% filter(Arcilla != -999)
da <- bd %>% filter(Da != -999)
clay <- tex %>% dplyr::select(ID, val = Arcilla)
sand <- tex %>% dplyr::select(ID, val = arena)
silt <- tex %>% dplyr::select(ID, val = Limo)
da <- da %>% dplyr::select(ID, val = Da)
# Resumen estadistico por propiedad
{
nprof <- clay %>% group_by(ID) %>% slice(1) %>% nrow
df1 <- clay %>% summarise(max = max(val),
min = min(val),
promedio = mean(val),
mediana = median(val),
desv = sd(val),
total = n()) %>%
mutate(n_profiles = nprof, propiedad = "Clay")
nprof <- sand %>% group_by(ID) %>% slice(1) %>% nrow
df2 <- sand %>% summarise(max = max(val),
min = min(val),
promedio = mean(val),
mediana = median(val),
desv = sd(val),
total = n())%>%
mutate(n_profiles = nprof, propiedad = "Sand")
nprof <- silt %>% group_by(ID) %>% slice(1) %>% nrow
df3 <- silt %>% summarise(max = max(val),
min = min(val),
promedio = mean(val),
mediana = median(val),
desv = sd(val),
total = n())%>%
mutate(n_profiles = nprof, propiedad = "Silt")
nprof <- da %>% group_by(ID) %>% slice(1) %>% nrow
df4 <- da %>% summarise(max = max(val),
min = min(val),
promedio = mean(val),
mediana = median(val),
desv = sd(val),
total = n())%>%
mutate(n_profiles = nprof, propiedad = "Bulk Density")
}
bd_summary <- bind_rows(df1,df2,df3,df4)
bd_summary
db= read_csv(here("data","soil_database","BD_soilprof_23MAR.csv"))
library(tidyverse)
db= read_csv(here("data","soil_database","BD_soilprof_23MAR.csv"))
library(here)
db= read_csv(here("data","soil_database","BD_soilprof_23MAR.csv"))
db %>% filter(PMP != -999) %>%
ggplot(aes(x = PMP))+
geom_histogram
db %>% filter(PMP != -999) %>%
ggplot(aes(x = PMP))+
geom_histogram()
db %>% filter(PMP > 0.5)
db %>% filter(PMP > 0.5) %>%
write_csv("pmp_gt_0.5.csv")
db %>% filter(FC > 0.5) %>%
write_csv("FC_gt_0.5.csv")
db %>% filter(CC > 0.5) %>%
write_csv("cc_gt_0.5.csv")
